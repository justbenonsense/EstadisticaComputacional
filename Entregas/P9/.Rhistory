2+2
sqrt(8)
7/2
5^(3/4)-log(2)
10%%4
5%%4
(1+1i)*(3-2i)
(1+1i)*(3-2i);(1+1i)(3-2i)
(1+1i)*(3-2i);(1+1i)/(3-2i)
#comentario
exp(2-3*
pi
)
Help
help
help()
help("log")
example(mean)
x <- rnorm(50)
y <- rnorm(50,mean=10,sd=2)
x
summary
summary(x)
summary(y)
hist(x)
plot(x,y)
fit<-lm(y~x)
summary(fit)
abline(fit)
x<-1:10
y<-seq(-pi,pi,length.out=10)
cbind(x,y)
matrix(x,2,5)
f <- outer(x, y, function(x, y) cos(y)/(1 + x^2))
f
contour(x, y, f)
contour(x, y, f, nlevels=15, add=TRUE)
image(x,y,f)
demo(graphics)
q()
# Cargamos los datos de hatco2.csv almacenandolos en un dataframe con nombre
# hatco donde las variables de tipo factor se identifiquen como tal
hatco<-read.csv(file="hatco2.csv",header=TRUE,stringsAsFactors=TRUE)
# Primero representamos graficamente los datos para observar la posible
# relacion entre la respuesta y las variables explicativas
plot(hatco[,c(6:13)])
hatco<-read.csv(file="hatco2.csv",header=TRUE,stringsAsFactors=TRUE)
setwd("~/Infomates/5º/C2/EC/Prácticas/Entregas/P9")
setwd("~/Infomates/5º/C2/EC/Prácticas/Entregas/P9")
hatco<-read.csv(file="hatco2.csv",header=TRUE,stringsAsFactors=TRUE)
# Cargamos los datos de hatco2.csv almacenandolos en un dataframe con nombre
# hatco donde las variables de tipo factor se identifiquen como tal
hatco<-read.csv(file="hatco2.csv",header=TRUE,stringsAsFactors=TRUE)
rm(list=ls(all=TRUE))
# --Ejercicio 1-------------------------------------------------------------------------
# Cargamos los datos de hatco2.csv almacenandolos en un dataframe con nombre
# hatco donde las variables de tipo factor se identifiquen como tal
hatco<-read.csv(file="hatco2.csv",header=TRUE,stringsAsFactors=TRUE)
# Primero representamos graficamente los datos para observar la posible
# relacion entre la respuesta y las variables explicativas
plot(hatco[,c(6:13)])
# Observamos el gráfico y comentamos...
# Podríamos ver la relación que hay entre la fidelidad y la velocidad, y entre
# la fidelidad y servconj.
# Por otro lado, podemos observar que hay una gran relación lineal entre
# servconj e imgfvent
# Ajustamos el modelo de regresion lineal multiple a las n=100 observaciones
mod1<-lm(fidelidad~velocidad+precio+flexprec+imgfabri+servconj+imgfvent+calidadp,hatco)
mod1
# Vamos a calcular el contraste de regresion y los coeficientes de determinacion
# con la funcion summary
summary(mod1)
# Calculamos la tabla ANOVA
anova(mod1)
# Significacion individual de las variables explicativass
# Para x1 no hay evidencia suficiente para rechazar la hip nula al 5% de significacion
# Repetimos el procedimiento anterior para otras percepciones x2...x7
# Las únicas percepciones para las que se rechazan la hipotesis nula al
# 5% de significacion son:
# flexprec y servconj, ya que sus p-valores se quedan por debajo de 0.05
# Para el resto de percepciones no evidencia suficiente de los datos
# para rechazar la hipotesis nula al 5% de signifcicacion, por lo que la
# percepcion del cliente ante dichas percepciones no parece influir
# significativamente en su fidelidad
# Significacion del termino constante
# Con el 5% no podríamos presencidir del termino constante en el modelo
# ya que su p-valor es 0.044, en cambio para el 1% si se podria
# Homocedasticidad
# Calculamos los residuos
residuos<-rstandard(mod1)
y_gorro<-mod1$fitted.values
# Representamos el grafico de dispersion de los pares (y_gorro,residuos)
plot(y_gorro,residuos)
# Represenntamos para cada percepcion x_j los grafos de dispersion de los pares
# (x_ij,r_i)
plot(hatco$empresa, residuos)
plot(hatco$velocidad, residuos)
plot(hatco$precio, residuos)
plot(hatco$flexprec, residuos)
plot(hatco$imgfabri, residuos)
plot(hatco$servconj, residuos)
plot(hatco$imgfvent, residuos)
plot(hatco$calidadp, residuos)
plot(hatco$fidelidad, residuos)
# Podemos observar que no hay ningun patron excepto en el ultimo grafico
library(knitr)
install.packages('knitr')
library(knitr)
spin('script8.R',knit=FALSE)
spin('Entrega9.R',knit=FALSE)
spin('script8.R',knit=FALSE)
