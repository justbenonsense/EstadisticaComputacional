---
title: "Repaso Parcial 2."
subtitle: " Estadistica Computacional. Curso 2021-2022."
author: "Carlota Valdivia Manzano."
date: "1 de Junio de 2022."
---

## Ejercicio 1
Establecemos la semilla del generador de números aleatorios

```{r }
set.seed(1)
```

Generamos 50 valores desde una distribución Chi-cuadrado con n= 30 grados de libertad y lo almacenamos en un vector y

```{r }
y<-rchisq(50, df = 30)
```

Generamos 50 valores desde una distribución Normal con media 30 y desviación típica 5
y lo almacenamos en un vector x

```{r }
x<-rnorm(50, mean = 30, sd = 5)
```

Calculamos la media, la desviación típica y los tres cuartiles de y

```{r }
mean_y<-mean(y)
sd_y<-sd(y)
quantile(y, c(0.25,0.5,0.75))
```

Representamos un histograma de los datos almacenados en y, y superponemos al histograma anterior la curva de la densidad Normal con media y desviación
típica la de los datos.
```{r }
hist(y, breaks="FD",freq=FALSE,main="Muestra Chi-cuadrado",ylim = c(0, 0.08))
lines(density(x),col='blue')
curve(dnorm(x,mean=mean_y, sd=sd_y),add=TRUE,col=2)

```



Representamos un gráfico probabilístico normal de los valores de y 

```{r }
qqnorm(y)
```

Representamos un gráfico de cajas de los valores de y

```{r }
boxplot(y)
```

Representamos un gráfico de cajas múltiples (2 cajas) que permita comparar la distribución
x e y

```{r }
boxplot(x, y, main = "Comparación de las distribuciones x e y")
```

Representamos un diagrama de dispersión de los valores de x (en el eje horizontal) frente
a los valores de y (en el eje vertical).

```{r }
plot(x, y, main = "Diagrama de dispersión")
```

Ajustamos un modelo de regresión lineal con los datos almacenados en x e y.

```{r }
mod <- lm(y ~ 1 + x)
```

Representamos el modelo ajustado sobre el diagrama de dispersión anterior

```{r }
plot(x, y, main = "Diagrama de dispersión")
abline(mod)
```

Borramos memoria

```{r }
rm(list=ls(all=TRUE))
```

## Ejercicio 2
Escribir una función que simule el lanzamiento de n dados
* La función tendrá un único argumento, el número de lanzamientos n, y tomará el valor 
  4 por defecto. 
* La función devolverá como posibles valores: TRUE, si se obtiene al menos un 6
                                              FALSE, en caso contrario

```{r }
lanzamiento.dados<-function(n=4)
{
    x<-sample(1:6,n,replace=FALSE)

    print(x)

    return(any(x == 6)) 
}
```

Utilizamos la función anterior para simular nsim=1000 jugadas de este juego, y calcular
la proporción de veces que se gana la apuesta de "obtener al menos un 6 en n=4 lanzamientos"

```{r }
nsim<-1000
x<-sapply(rep(4,nsim), lanzamiento.dados)
mean(x)
```

Comparamos el resultado con la probabilidad exacta que es 1 - (5/6)^n

```{r }
1-(5/6)^4
```

Borramos memoria

```{r }
rm(list=ls(all=TRUE))
```

## Ejercicio 3
Utilizando el método de inversión vamos a generar n=1000 valores de una distribución 
Pareto con parámetros a=5 y b=4.

```{r }
n<-1000
a<-5
b<-4

set.seed(1)
u<-runif(n)
```

Evaluamos usando gráficos y el contraste de Kolmogorov-Smirnow que en efecto los valores
generados provienen de dicha distribución.

```{r }
inversa.pareto<-function(u, a, b) {
  (b/(1-u)^(1/a))
}

x<-inversa.pareto(u,a,b)
```

Calculamos la funciones de densidad y distribución

```{r}
f.densidad<-function(x, a, b) {
  ifelse(x>=b, (a*b^a)/(x^(a+1)), 0)
}

f.distribucion<-function(x, a, b) {
  ifelse(x>=b, 1-(b/x)^a, 0)
}
```

Creamos el gráfico. 

```{r }
hist(x, breaks="FD", freq=FALSE, main="Método de inversión", xlim=c(0,20),ylim=c(0,1.3))
lines(density(x), col="blue")
curve(f.densidad(x,a,b),add=TRUE,col=2)
```

Evaluamos el contraste de Kolmogorov-Smirnow

```{r }
ks.test(x,f.distribucion,a=a,b=b)
```

Borramos memoria

```{r }
rm(list=ls(all=TRUE))
```

## Ejercicio 4
Utilizando la intregración de Monte Carlo se pide aproximar la integral y calcular el error
de aproximación.
Para ello consideramos un número suficientemene grande de simulaciones, evaluando la 
convergencia mediante un gráfico.
Definimos la función a integrar

```{r }
h<-function(x) {
  1/(1+x^2)
}
```

Visualizamos la función en el dominio de integración

```{r }
curve(h,0,1)
```

Fijamos el número de simulaciones

```{r }
nsim<-1000
```

Calculamos la aproximación

```{r }
set.seed(1)
x<-runif(nsim)
hx<-sapply(x,h)
mean(h)
```

Valor exacto

```{r }
pi/4
```

Aproximaciones para $n=1,...,nsim$

```{r }
estim<-cumsum(hx)/(1:nsim)
```

Errores de estimación correspondientes

```{r }
estim.err<-sqrt(cumsum((hx-estim)^2))/(1:nsim)

plot(1:nsim,estim,type='l',ylab='Aproximación y límites de error', xlab='Número de simulaciones')
z<-qnorm(0.025,lower.tail = FALSE)
lines(estim - z*estim.err,col='blue',lwd=2,lty=3)
lines(estim + z*estim.err,col='blue',lwd=2,lty=3)
abline(h=pi/4,col=2)
```

Aproximación final y su error

```{r }
estim[nsim]
estim.err[nsim]
```

Borramos memoria

```{r }
rm(list=ls(all=TRUE))
```

